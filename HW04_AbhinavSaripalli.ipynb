{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abhinav Saripalli\n",
    "# 2020/02/07\n",
    "# CS301-006, Professor Watson\n",
    "# HW04 Solution\n",
    "# using DataFrame with pandas along with mean and standard deviation\n",
    "# https://github.com/as2745/Homework\n",
    "# https://github.com/as2745/Homework/blob/master/HW04_AbhinavSaripalli.ipynb\n",
    "# Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_percent_nans(df, str):\n",
    "    data=df[str]\n",
    "    #print(data)\n",
    "    num=data.isnull().sum()\n",
    "    nump=(num/data.shape[0])*100\n",
    "    return nump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Province/State\" column has 24.45% empty values\n",
      "The \"Country/Region\" column has 0.00% empty values\n",
      "The \"Last Update\" column has 0.00% empty values\n",
      "The \"Confirmed\" column has 1.60% empty values\n",
      "The \"Suspected\" column has 95.31% empty values\n",
      "The \"Recovered\" column has 46.67% empty values\n",
      "The \"Death\" column has 53.22% empty values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_path='C://Users//Abhinav//Desktop//2019_nCoV_20200121_20200206.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "#data1=data['Province/State']\n",
    "#print(np.array(data1))\n",
    "for col in data.columns:\n",
    "    print('The \\\"{}\\\" column has {:.2f}% empty values'.format(col, get_percent_nans(data, col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Mainland China\n",
      "70    Mainland China\n",
      "Name: Country/Region, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data_path='C://Users//Abhinav//Desktop//2019_nCoV_20200121_20200206.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "max=np.max(data['Death'])\n",
    "data1=data.loc[data['Death']==max]\n",
    "print(data1['Country/Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1532    Hong Kong\n",
      "1581    Hong Kong\n",
      "1623    Hong Kong\n",
      "Name: Country/Region, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 3\n",
    "import numpy as np\n",
    "data_path='C://Users//Abhinav//Desktop//2019_nCoV_20200121_20200206.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "max=np.max(data['Suspected'])\n",
    "data1=data.loc[data['Suspected']==max]\n",
    "print(data1['Country/Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country/Region\n",
      "Thailand    4.5\n",
      "Name: Recovered, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 4\n",
    "import numpy as np\n",
    "data_path='C://Users//Abhinav//Desktop//2019_nCoV_20200121_20200206.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data1=data[[\"Country/Region\", \"Recovered\"]]\n",
    "num=data['Recovered'].groupby([data['Country/Region']]).mean()\n",
    "#avg=np.ma.average(data['Recovered'])\n",
    "#data1=data.loc[data['Recovered']==avg]\n",
    "#print(avg)\n",
    "data1=num.sort_values(ascending=False)[1:2]\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBLEM 5\n",
    "import pandas as pd\n",
    "import pycountry_convert as pc\n",
    "def returndict(data_path):\n",
    "    #data_path='C://Users//Abhinav//Desktop//2019_nCoV_20200121_20200206.csv'\n",
    "    #print(data_path)\n",
    "    data = pd.read_csv(data_path)\n",
    "    dict={}\n",
    "    for countries in data['Country/Region']:\n",
    "        if countries=='Mainland China':\n",
    "            country='CN'\n",
    "        elif countries == 'UK':\n",
    "            country='GB'\n",
    "        else:\n",
    "            country=pc.country_name_to_country_alpha2(countries)\n",
    "        if countries not in dict:\n",
    "            dict[countries]=pc.country_alpha2_to_continent_code(country)\n",
    "        else:\n",
    "            continue\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Asia'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem 6\n",
    "import pandas as pd\n",
    "import pycountry_convert as pc\n",
    "def get_continent(country):\n",
    "    data_path='C://Users//Abhinav//Desktop//2019_nCoV_20200121_20200206.csv'\n",
    "    dict=returndict(data_path)\n",
    "    continents ={'NA': 'North America','SA': 'South America', 'AS': 'Asia','OC': 'Australia','AF': 'Africa', 'EU': 'Europe'}\n",
    "    #for continent in dict.values():    \n",
    "    return continents[dict[country]]\n",
    "    #print(country)\n",
    "get_continent(\"Mainland China\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Province/State  Country/Region   Last Update  Confirmed  Suspected  \\\n",
      "0             Hubei  Mainland China  2/5/20 16:43    16678.0        NaN   \n",
      "1         Guangdong  Mainland China  2/5/20 13:23      895.0        NaN   \n",
      "2          Zhejiang  Mainland China  2/5/20 15:13      895.0        NaN   \n",
      "3             Henan  Mainland China  2/5/20 15:03      764.0        NaN   \n",
      "4             Hunan  Mainland China  2/5/20 15:23      661.0        NaN   \n",
      "...             ...             ...           ...        ...        ...   \n",
      "1872   Heilongjiang  Mainland China     1/21/2020        NaN        1.0   \n",
      "1873            NaN           Japan     1/21/2020        1.0        NaN   \n",
      "1874            NaN        Thailand     1/21/2020        2.0        NaN   \n",
      "1875            NaN     South Korea     1/21/2020        1.0        NaN   \n",
      "1876     Washington   United States     1/21/2020        1.0        NaN   \n",
      "\n",
      "      Recovered  Death      Continent  \n",
      "0         538.0  479.0           Asia  \n",
      "1          49.0    0.0           Asia  \n",
      "2          78.0    0.0           Asia  \n",
      "3          47.0    2.0           Asia  \n",
      "4          54.0    0.0           Asia  \n",
      "...         ...    ...            ...  \n",
      "1872        NaN    NaN           Asia  \n",
      "1873        NaN    NaN           Asia  \n",
      "1874        NaN    NaN           Asia  \n",
      "1875        NaN    NaN           Asia  \n",
      "1876        NaN    NaN  North America  \n",
      "\n",
      "[1877 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#Problem 7\n",
    "import pandas as pd\n",
    "data_path='C://Users//Abhinav//Desktop//2019_nCoV_20200121_20200206.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "dict=returndict(data_path)\n",
    "conts=[]\n",
    "for countries in data['Country/Region']:\n",
    "    #print(get_continent(countries))\n",
    "    conts.append(get_continent(countries))\n",
    "data1=data.assign(Continent= conts)\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continent\n",
      "Africa                1.0\n",
      "Asia             304958.0\n",
      "Australia           238.0\n",
      "Europe              421.0\n",
      "North America       273.0\n",
      "South America         0.0\n",
      "Name: Confirmed, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Problem 8\n",
    "import pandas as pd\n",
    "data_path='C://Users//Abhinav//Desktop//2019_nCoV_20200121_20200206.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "dict=returndict(data_path)\n",
    "conts=[]\n",
    "for countries in data['Country/Region']:\n",
    "    #print(get_continent(countries))\n",
    "    conts.append(get_continent(countries))\n",
    "data1=data.assign(Continent= conts)\n",
    "num=data1['Confirmed'].groupby([data1['Continent']]).sum()\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
